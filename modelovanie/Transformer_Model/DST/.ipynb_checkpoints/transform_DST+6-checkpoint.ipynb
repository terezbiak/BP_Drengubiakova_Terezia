{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ef9323-0a7d-4c7a-a1e6-d6b4a03b0e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 13:24:15.709342: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Conv1D, LSTM, MaxPooling1D, Flatten, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from scipy.special import expit, logit\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, MultiHeadAttention, Dropout, LayerNormalization, Dense\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Dense, Input, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d43abb-87e8-4c68-9e99-1fcdc0367cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_omni.csv')\n",
    "test = pd.read_csv('test_omni.csv')\n",
    "features = ['time1', 'DST', 'DST+1']\n",
    "test = test[features]\n",
    "train = train[features]\n",
    "train['time1']=pd.to_datetime(train['time1'])\n",
    "test['time1']=pd.to_datetime(test['time1'])\n",
    "\n",
    "y_col='DST+1'\n",
    "valid_size = int(len(train) * 0.2)\n",
    "valid = train.iloc[-valid_size:,:].copy()\n",
    "train = train.iloc[:-valid_size,:].copy()\n",
    "\n",
    "y_train = train[y_col].values.copy()\n",
    "X_train = train['DST'].values.copy()\n",
    "y_val = valid[y_col].values.copy()\n",
    "X_val = valid['DST'].values.copy()\n",
    "y_test = test[y_col].values.copy()\n",
    "X_test = test['DST'].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d4e002-dddc-4ad9-8bad-c7638095a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 6 \n",
    "n_features= len(X_train)  \n",
    "b_size = 256  \n",
    "\n",
    "train_generator = TimeseriesGenerator(X_train, y_train, length=n_input, batch_size=b_size)\n",
    "val_generator = TimeseriesGenerator(X_val, y_val, length=n_input, batch_size=b_size)\n",
    "test_generator = TimeseriesGenerator(X_test, y_test, length=n_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa04d2b-9f0e-4e3d-ad51-c7b16d1a97a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 13:38:03.874217: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 6, 1)]            0         \n",
      "                                                                 \n",
      " transformer_encoder_layer (  (None, 6, 64)            66688     \n",
      " TransformerEncoderLayer)                                        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 384)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 385       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,073\n",
      "Trainable params: 67,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class TransformerEncoderLayer(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, input_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerEncoderLayer, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.rate = rate\n",
    "        self.input_proj = Dense(embed_dim)\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        inputs_proj = self.input_proj(inputs)\n",
    "        attn_output = self.att(inputs_proj, inputs_proj)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs_proj + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'ff_dim': self.ff_dim,\n",
    "            'input_dim': self.input_dim,\n",
    "            'rate': self.rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def build_model(input_shape, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = TransformerEncoderLayer(embed_dim, num_heads, ff_dim, input_shape[-1], rate)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation='linear')(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\n",
    "model = build_model((6, 1), embed_dim=64, num_heads=2, ff_dim=256)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17749e5-32c6-411b-ab2c-36cb3a7924aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = \"1h_transform.keras\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_mae\", mode=\"min\", patience=25)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb916a-799c-48e0-aaa3-cd91fab2febf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "894/896 [============================>.] - ETA: 0s - loss: 193.4501 - mae: 7.1940\n",
      "Epoch 1: val_mae improved from inf to 6.67314, saving model to 1h_transform.keras\n",
      "896/896 [==============================] - 23s 23ms/step - loss: 193.0794 - mae: 7.1868 - val_loss: 194.1874 - val_mae: 6.6731\n",
      "Epoch 2/200\n",
      "894/896 [============================>.] - ETA: 0s - loss: 76.4736 - mae: 4.7046\n",
      "Epoch 2: val_mae improved from 6.67314 to 4.42962, saving model to 1h_transform.keras\n",
      "896/896 [==============================] - 21s 23ms/step - loss: 76.3408 - mae: 4.7004 - val_loss: 109.8702 - val_mae: 4.4296\n",
      "Epoch 3/200\n",
      "896/896 [==============================] - ETA: 0s - loss: 52.1986 - mae: 4.1520\n",
      "Epoch 3: val_mae did not improve from 4.42962\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 52.1986 - mae: 4.1520 - val_loss: 91.1497 - val_mae: 4.8998\n",
      "Epoch 4/200\n",
      "893/896 [============================>.] - ETA: 0s - loss: 65.7777 - mae: 4.6976\n",
      "Epoch 4: val_mae improved from 4.42962 to 3.94108, saving model to 1h_transform.keras\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 65.6183 - mae: 4.6927 - val_loss: 72.8642 - val_mae: 3.9411\n",
      "Epoch 5/200\n",
      "283/896 [========>.....................] - ETA: 12s - loss: 36.6270 - mae: 3.5863"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, validation_data=val_generator, epochs=200, verbose=1, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb26874-787e-46ae-81dc-d531e648a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('1h_transform.keras', custom_objects={'TransformerEncoderLayer': TransformerEncoderLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a571306-f07a-4d2a-95bf-8a1396aecab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee50d150-532e-4b14-817f-35fa501f75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test[:-n_input], y_pred.reshape(-1))\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c85f39-4837-4a9d-98ff-84b3007af120",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(val_generator)\n",
    "\n",
    "true_labels_val = np.where(y_val[n_input:] <= -20, 1, 0)  \n",
    "\n",
    "def calculate_mcc(y_true, y_pred):\n",
    "    return matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "thresholds = np.arange(-10, -40, -0.1)\n",
    "mcc_scores = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    predictions = np.where(y_val_pred <= thresh, 1, 0)\n",
    "    mcc = calculate_mcc(true_labels_val, predictions)\n",
    "    mcc_scores.append(mcc)\n",
    "\n",
    "best_threshold_mcc = thresholds[np.argmax(mcc_scores)]\n",
    "best_mcc = max(mcc_scores)\n",
    "\n",
    "print(\"Best Threshold for MCC on Validation Set:\", best_threshold_mcc)\n",
    "print(\"Best MCC on Validation Set:\", best_mcc)\n",
    "best_threshold_mcc_rounded = round(best_threshold_mcc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d03dc2-b7ba-4e55-8837-337aa331623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = np.where(y_pred <= best_threshold_mcc_rounded, 1, 0)\n",
    "y_test2 = np.where(y_test[n_input:]  <= -20, 1, 0)\n",
    "\n",
    "cm = confusion_matrix(y_test2, y_pred2)\n",
    "print(\"Confusion matrix: \\n\" + str(cm))\n",
    "\n",
    "print(classification_report(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41f7df5-667a-4d01-b6b1-6da39d50f902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
