{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ae642c-67c7-48fc-9faa-54906e46f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 18:20:24.465166: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Conv1D, LSTM, MaxPooling1D, Flatten, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from scipy.special import expit, logit\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, MultiHeadAttention, Dropout, LayerNormalization, Dense\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Dense, Input, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83d176a1-e03a-4527-83b2-ec184f0bc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_omni.csv')\n",
    "test = pd.read_csv('test_omni.csv')\n",
    "train['BZ_GSM'] = train['BZ_GSM'].fillna(train['BZ_GSM'].mean()) \n",
    "test['BZ_GSM'] = test['BZ_GSM'].fillna(test['BZ_GSM'].mean())\n",
    "features = ['time1', 'DST', 'DST+1', 'BZ_GSM', 'KP']\n",
    "test = test[features]\n",
    "train = train[features]\n",
    "train['time1']=pd.to_datetime(train['time1'])\n",
    "test['time1']=pd.to_datetime(test['time1'])\n",
    "predicators = [\"DST\", \"BZ_GSM\", \"KP\"]\n",
    "y_col='DST+1'\n",
    "valid_size = int(len(train) * 0.2)\n",
    "valid = train.iloc[-valid_size:,:].copy()\n",
    "train = train.iloc[:-valid_size,:].copy()\n",
    "\n",
    "y_train = train[y_col].values.copy()\n",
    "X_train = train[predicators].values.copy()\n",
    "y_val = valid[y_col].values.copy()\n",
    "X_val = valid[predicators].values.copy()\n",
    "y_test = test[y_col].values.copy()\n",
    "X_test = test[predicators].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a884202-da06-4f52-a0fb-a60461faefd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 6  \n",
    "n_features= len(X_train)  \n",
    "b_size = 256  \n",
    "\n",
    "train_generator = TimeseriesGenerator(X_train, y_train, length=n_input, batch_size=b_size)\n",
    "val_generator = TimeseriesGenerator(X_val, y_val, length=n_input, batch_size=b_size)\n",
    "test_generator = TimeseriesGenerator(X_test, y_test, length=n_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6436f68f-c696-4bb9-a87c-b95c7d42a9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 18:21:25.144420: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 6, 3)]            0         \n",
      "                                                                 \n",
      " transformer_encoder_layer (  (None, 6, 64)            66816     \n",
      " TransformerEncoderLayer)                                        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 384)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 385       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,201\n",
      "Trainable params: 67,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class TransformerEncoderLayer(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, input_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerEncoderLayer, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.rate = rate\n",
    "        self.input_proj = Dense(embed_dim)\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        inputs_proj = self.input_proj(inputs)\n",
    "        attn_output = self.att(inputs_proj, inputs_proj)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs_proj + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'ff_dim': self.ff_dim,\n",
    "            'input_dim': self.input_dim,\n",
    "            'rate': self.rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def build_model(input_shape, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = TransformerEncoderLayer(embed_dim, num_heads, ff_dim, input_shape[-1], rate)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation='linear')(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\n",
    "model = build_model((6, 3), embed_dim=64, num_heads=2, ff_dim=256)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f25d3c3d-5d7f-492f-949c-7d5a4d7431ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = \"1h_BZ_GSM_transform.keras\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_mae\", mode=\"min\", patience=25)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa36bc-f66e-4998-b510-d126b155c7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "895/896 [============================>.] - ETA: 0s - loss: 152.0046 - mae: 6.7139\n",
      "Epoch 1: val_mae improved from inf to 13.36084, saving model to 1h_BZ_GSM_transform.keras\n",
      "896/896 [==============================] - 24s 25ms/step - loss: 152.0052 - mae: 6.7161 - val_loss: 359.5879 - val_mae: 13.3608\n",
      "Epoch 2/200\n",
      "894/896 [============================>.] - ETA: 0s - loss: 64.7915 - mae: 4.5889\n",
      "Epoch 2: val_mae improved from 13.36084 to 4.49749, saving model to 1h_BZ_GSM_transform.keras\n",
      "896/896 [==============================] - 20s 23ms/step - loss: 64.7219 - mae: 4.5872 - val_loss: 99.4381 - val_mae: 4.4975\n",
      "Epoch 3/200\n",
      "895/896 [============================>.] - ETA: 0s - loss: 50.8663 - mae: 4.1392\n",
      "Epoch 3: val_mae improved from 4.49749 to 3.93577, saving model to 1h_BZ_GSM_transform.keras\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 50.8305 - mae: 4.1383 - val_loss: 75.8728 - val_mae: 3.9358\n",
      "Epoch 4/200\n",
      "895/896 [============================>.] - ETA: 0s - loss: 42.8760 - mae: 3.9157\n",
      "Epoch 4: val_mae did not improve from 3.93577\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 42.8444 - mae: 3.9147 - val_loss: 71.4524 - val_mae: 4.1777\n",
      "Epoch 5/200\n",
      "896/896 [==============================] - ETA: 0s - loss: 40.0248 - mae: 3.9140\n",
      "Epoch 5: val_mae did not improve from 3.93577\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 40.0248 - mae: 3.9140 - val_loss: 97.0084 - val_mae: 5.1319\n",
      "Epoch 6/200\n",
      "894/896 [============================>.] - ETA: 0s - loss: 35.3766 - mae: 3.6533\n",
      "Epoch 6: val_mae did not improve from 3.93577\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 35.3630 - mae: 3.6537 - val_loss: 63.0962 - val_mae: 4.1979\n",
      "Epoch 7/200\n",
      "895/896 [============================>.] - ETA: 0s - loss: 31.5516 - mae: 3.5133\n",
      "Epoch 7: val_mae did not improve from 3.93577\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 31.5712 - mae: 3.5150 - val_loss: 173.2505 - val_mae: 7.8602\n",
      "Epoch 8/200\n",
      "895/896 [============================>.] - ETA: 0s - loss: 32.1663 - mae: 3.5647\n",
      "Epoch 8: val_mae did not improve from 3.93577\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 32.2455 - mae: 3.5682 - val_loss: 56.1869 - val_mae: 3.9379\n",
      "Epoch 9/200\n",
      "894/896 [============================>.] - ETA: 0s - loss: 35.1532 - mae: 3.6062\n",
      "Epoch 9: val_mae improved from 3.93577 to 3.65200, saving model to 1h_BZ_GSM_transform.keras\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 35.1366 - mae: 3.6066 - val_loss: 54.1769 - val_mae: 3.6520\n",
      "Epoch 10/200\n",
      "377/896 [===========>..................] - ETA: 10s - loss: 28.8786 - mae: 3.4274"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, validation_data=val_generator, epochs=200, verbose=1, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160cb204-59fa-4bf2-b85e-3be293a8b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('1h_BZ_GSM_transform.keras', custom_objects={'TransformerEncoderLayer': TransformerEncoderLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0c9d1-fab9-4d81-b9b9-d6902840539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a462a9b-e7e2-45e2-b30f-a7ee61144472",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test[:-n_input], y_pred.reshape(-1))\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f72acd3-5552-4e73-b080-625788a602c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(val_generator)\n",
    "\n",
    "true_labels_val = np.where(y_val[n_input:] <= -20, 1, 0)  # Adjust n_input as per your setup\n",
    "\n",
    "def calculate_mcc(y_true, y_pred):\n",
    "    return matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "thresholds = np.arange(-10, -40, -0.1)\n",
    "mcc_scores = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    predictions = np.where(y_val_pred <= thresh, 1, 0)\n",
    "    mcc = calculate_mcc(true_labels_val, predictions)\n",
    "    mcc_scores.append(mcc)\n",
    "\n",
    "best_threshold_mcc = thresholds[np.argmax(mcc_scores)]\n",
    "best_mcc = max(mcc_scores)\n",
    "\n",
    "print(\"Best Threshold for MCC on Validation Set:\", best_threshold_mcc)\n",
    "print(\"Best MCC on Validation Set:\", best_mcc)\n",
    "best_threshold_mcc_rounded = round(best_threshold_mcc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44adfea5-eec4-4fb3-8525-a7156bd7c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = np.where(y_pred <= best_threshold_mcc_rounded, 1, 0)\n",
    "y_test2 = np.where(y_test[n_input:]  <= -20, 1, 0)\n",
    "\n",
    "cm = confusion_matrix(y_test2, y_pred2)\n",
    "print(\"Confusion matrix: \\n\" + str(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fffb07-76df-4eac-8551-20c50c4675a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9695170-2caf-4ce4-abf6-9b5d8590ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"time\": test['time1'][n_input:],\"y_true\": y_test[n_input:].reshape(-1) , \"y_predict\": y_pred.reshape(-1)})\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Predicting the change in DST Index')\n",
    "plt.plot(df['time'],df['y_true'], label='Skutočné hodnoty')\n",
    "plt.plot(df['time'],df['y_predict'], label='Predikované hodnoty')\n",
    "plt.legend()\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467fba44-d16a-4ed2-b88e-b782fa973c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = cm.ravel()\n",
    "ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "MCC = matthews_corrcoef(y_test2, y_pred2)\n",
    "print(\"ACC={}\".format(ACC))\n",
    "print(\"MCC={}\".format(MCC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800dae1-b9cf-454f-9a13-870dcd8f80a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
