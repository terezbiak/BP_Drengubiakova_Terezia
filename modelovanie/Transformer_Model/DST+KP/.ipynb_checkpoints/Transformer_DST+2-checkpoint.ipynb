{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253f73f4-9541-4e2b-a5e8-3671365db708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 16:37:10.392570: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Conv1D, LSTM, MaxPooling1D, Flatten, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from scipy.special import expit, logit\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, MultiHeadAttention, Dropout, LayerNormalization, Dense\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Dense, Input, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb39fad-4954-4c25-80cb-fb881404a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_omni.csv')\n",
    "test = pd.read_csv('test_omni.csv')\n",
    "features = ['time1', 'DST', 'DST+1', 'KP']\n",
    "test = test[features]\n",
    "train = train[features]\n",
    "train['time1']=pd.to_datetime(train['time1'])\n",
    "test['time1']=pd.to_datetime(test['time1'])\n",
    "predicators = [\"DST\", \"KP\"]\n",
    "y_col='DST+1'\n",
    "valid_size = int(len(train) * 0.2)\n",
    "valid = train.iloc[-valid_size:,:].copy()\n",
    "train = train.iloc[:-valid_size,:].copy()\n",
    "\n",
    "\n",
    "y_train = train[y_col].values.copy()\n",
    "X_train = train[predicators].values.copy()\n",
    "y_val = valid[y_col].values.copy()\n",
    "X_val = valid[predicators].values.copy()\n",
    "y_test = test[y_col].values.copy()\n",
    "X_test = test[predicators].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f3bf570-efc0-4586-91f6-aa364f46de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 6  \n",
    "n_features= len(X_train)  \n",
    "b_size = 256\n",
    "\n",
    "train_generator = TimeseriesGenerator(X_train, y_train, length=n_input, batch_size=b_size)\n",
    "val_generator = TimeseriesGenerator(X_val, y_val, length=n_input, batch_size=b_size)\n",
    "test_generator = TimeseriesGenerator(X_test, y_test, length=n_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa2a1a7-f757-4326-8502-ee9d8e84296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 16:38:08.304249: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 6, 2)]            0         \n",
      "                                                                 \n",
      " transformer_encoder_layer (  (None, 6, 64)            66752     \n",
      " TransformerEncoderLayer)                                        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 384)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 385       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,137\n",
      "Trainable params: 67,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class TransformerEncoderLayer(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, input_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerEncoderLayer, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.rate = rate\n",
    "        self.input_proj = Dense(embed_dim)\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        inputs_proj = self.input_proj(inputs)\n",
    "        attn_output = self.att(inputs_proj, inputs_proj)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs_proj + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'ff_dim': self.ff_dim,\n",
    "            'input_dim': self.input_dim,\n",
    "            'rate': self.rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def build_model(input_shape, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = TransformerEncoderLayer(embed_dim, num_heads, ff_dim, input_shape[-1], rate)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation='linear')(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "model = build_model((6, 2), embed_dim=64, num_heads=2, ff_dim=256)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb01967-ae38-4bde-831b-80f3b80abf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = \"1h_KP_transform.keras\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_mae\", mode=\"min\", patience=25)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e4b9a-a0d5-47f1-9689-9ccd2d1d2d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "895/896 [============================>.] - ETA: 0s - loss: 185.4998 - mae: 7.3912\n",
      "Epoch 1: val_mae improved from inf to 5.63250, saving model to 1h_KP_transform.keras\n",
      "896/896 [==============================] - 23s 23ms/step - loss: 185.3057 - mae: 7.3860 - val_loss: 187.4047 - val_mae: 5.6325\n",
      "Epoch 2/200\n",
      "894/896 [============================>.] - ETA: 0s - loss: 69.3996 - mae: 4.5382\n",
      "Epoch 2: val_mae improved from 5.63250 to 4.51043, saving model to 1h_KP_transform.keras\n",
      "896/896 [==============================] - 20s 23ms/step - loss: 69.2924 - mae: 4.5355 - val_loss: 106.9646 - val_mae: 4.5104\n",
      "Epoch 3/200\n",
      "894/896 [============================>.] - ETA: 0s - loss: 56.3046 - mae: 4.3866\n",
      "Epoch 3: val_mae improved from 4.51043 to 4.09592, saving model to 1h_KP_transform.keras\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 56.2063 - mae: 4.3828 - val_loss: 78.2677 - val_mae: 4.0959\n",
      "Epoch 4/200\n",
      "896/896 [==============================] - ETA: 0s - loss: 53.5538 - mae: 4.3233\n",
      "Epoch 4: val_mae improved from 4.09592 to 4.08454, saving model to 1h_KP_transform.keras\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 53.5538 - mae: 4.3233 - val_loss: 74.8478 - val_mae: 4.0845\n",
      "Epoch 5/200\n",
      "893/896 [============================>.] - ETA: 0s - loss: 38.2010 - mae: 3.8071\n",
      "Epoch 5: val_mae improved from 4.08454 to 3.99511, saving model to 1h_KP_transform.keras\n",
      "896/896 [==============================] - 19s 22ms/step - loss: 38.1454 - mae: 3.8047 - val_loss: 58.9151 - val_mae: 3.9951\n",
      "Epoch 6/200\n",
      "893/896 [============================>.] - ETA: 0s - loss: 39.2687 - mae: 3.8861\n",
      "Epoch 6: val_mae improved from 3.99511 to 3.73035, saving model to 1h_KP_transform.keras\n",
      "896/896 [==============================] - 19s 21ms/step - loss: 39.1907 - mae: 3.8832 - val_loss: 55.2834 - val_mae: 3.7303\n",
      "Epoch 7/200\n",
      "894/896 [============================>.] - ETA: 0s - loss: 36.5793 - mae: 3.7635\n",
      "Epoch 7: val_mae improved from 3.73035 to 3.62811, saving model to 1h_KP_transform.keras\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 36.5339 - mae: 3.7615 - val_loss: 50.6435 - val_mae: 3.6281\n",
      "Epoch 8/200\n",
      "895/896 [============================>.] - ETA: 0s - loss: 33.8896 - mae: 3.6805\n",
      "Epoch 8: val_mae did not improve from 3.62811\n",
      "896/896 [==============================] - 19s 21ms/step - loss: 33.9333 - mae: 3.6851 - val_loss: 182.9757 - val_mae: 7.9970\n",
      "Epoch 9/200\n",
      "896/896 [==============================] - ETA: 0s - loss: 35.1533 - mae: 3.7348\n",
      "Epoch 9: val_mae did not improve from 3.62811\n",
      "896/896 [==============================] - 20s 22ms/step - loss: 35.1533 - mae: 3.7348 - val_loss: 58.1346 - val_mae: 4.3441\n",
      "Epoch 10/200\n",
      "895/896 [============================>.] - ETA: 0s - loss: 27.9383 - mae: 3.3911\n",
      "Epoch 10: val_mae did not improve from 3.62811\n",
      "896/896 [==============================] - 19s 21ms/step - loss: 27.9237 - mae: 3.3906 - val_loss: 44.5800 - val_mae: 3.6617\n",
      "Epoch 11/200\n",
      "895/896 [============================>.] - ETA: 0s - loss: 34.7381 - mae: 3.7054\n",
      "Epoch 11: val_mae did not improve from 3.62811\n",
      "896/896 [==============================] - 19s 21ms/step - loss: 34.7258 - mae: 3.7052 - val_loss: 60.1463 - val_mae: 4.0771\n",
      "Epoch 12/200\n",
      "895/896 [============================>.] - ETA: 0s - loss: 27.6019 - mae: 3.3865\n",
      "Epoch 12: val_mae improved from 3.62811 to 3.55550, saving model to 1h_KP_transform.keras\n",
      "896/896 [==============================] - 19s 22ms/step - loss: 27.7183 - mae: 3.3896 - val_loss: 42.2613 - val_mae: 3.5555\n",
      "Epoch 13/200\n",
      "895/896 [============================>.] - ETA: 0s - loss: 31.3828 - mae: 3.5353\n",
      "Epoch 13: val_mae did not improve from 3.55550\n",
      "896/896 [==============================] - 19s 21ms/step - loss: 31.3699 - mae: 3.5350 - val_loss: 43.0810 - val_mae: 3.6555\n",
      "Epoch 14/200\n",
      "135/896 [===>..........................] - ETA: 15s - loss: 27.2362 - mae: 3.1870"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, validation_data=val_generator, epochs=200, verbose=1, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c22c7-b549-4c4d-a6e2-096f3ef6e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model( '1h_KP_transform.keras', custom_objects={'TransformerEncoderLayer': TransformerEncoderLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e37699-4e39-436f-8b99-971ded3a35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9bc210-4fac-4ba3-b644-618ec50eb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test[:-6], y_pred.reshape(-1))\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5fa96f-eb79-4a18-8f5f-ccc92edd5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(val_generator)\n",
    "\n",
    "true_labels_val = np.where(y_val[n_input:] <= -20, 1, 0)  \n",
    "\n",
    "def calculate_mcc(y_true, y_pred):\n",
    "    return matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "thresholds = np.arange(-10, -40, -0.1)\n",
    "mcc_scores = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    predictions = np.where(y_val_pred <= thresh, 1, 0)\n",
    "    mcc = calculate_mcc(true_labels_val, predictions)\n",
    "    mcc_scores.append(mcc)\n",
    "\n",
    "best_threshold_mcc = thresholds[np.argmax(mcc_scores)]\n",
    "best_mcc = max(mcc_scores)\n",
    "\n",
    "print(\"Best Threshold for MCC on Validation Set:\", best_threshold_mcc)\n",
    "print(\"Best MCC on Validation Set:\", best_mcc)\n",
    "best_threshold_mcc_rounded = round(best_threshold_mcc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a60a4-312d-49af-b434-62bb5321358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = np.where(y_pred <= best_threshold_mcc_rounded, 1, 0)\n",
    "y_test2 = np.where(y_test[n_input:]  <= -20, 1, 0)\n",
    "\n",
    "cm = confusion_matrix(y_test2, y_pred2)\n",
    "print(\"Confusion matrix: \\n\" + str(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf261e-9c6d-41e5-b29a-610944c0209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53e62e-9d40-4678-9358-b0a58302c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"time\": test['time1'][n_input:],\"y_true\": y_test[n_input:].reshape(-1) , \"y_predict\": y_pred.reshape(-1)})\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Predicting the change in DST Index')\n",
    "plt.plot(df['time'],df['y_true'], label='Skutočné hodnoty')\n",
    "plt.plot(df['time'],df['y_predict'], label='Predikované hodnoty')\n",
    "plt.legend()\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c622248e-eb1a-450b-b45a-ac09a38e0343",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = cm.ravel()\n",
    "ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "MCC = matthews_corrcoef(y_test2, y_pred2)\n",
    "print(\"ACC={}\".format(ACC))\n",
    "print(\"MCC={}\".format(MCC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2583efc-7edd-413e-a7f0-17bbf92681d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
